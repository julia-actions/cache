name: CI

on:
  push:
    branches:
      - main
    paths:
      - 'action.yml'
      - 'handle_caches.jl'
      - '.github/**'
  pull_request:
    paths:
      - 'action.yml'
      - 'handle_caches.jl'
      - '.github/**'

# needed to allow julia-actions/cache to delete old caches that it has created
permissions:
  actions: write
  contents: read

jobs:
  generate-prefix:
    runs-on: ubuntu-latest
    outputs:
      cache-prefix: ${{ steps.name.outputs.cache-prefix }}
    steps:
    - name: Generate random cache-prefix
      id: name
      run: |
        cache_prefix=$(head -n 100 </dev/urandom | shasum -a 256 | cut -d ' ' -f 1)
        echo "cache-prefix=$cache_prefix" >>"$GITHUB_OUTPUT"

  test-save:
    needs: generate-prefix
    runs-on: ${{ matrix.os }}
    outputs:
      cache-name: ${{ steps.cache-name.outputs.cache-name }}
    strategy:
      matrix:
        dep:
          - name: pandoc_jll
            version: "3"
            invalid-chars: ","  # Use invalid characters in job matrix to ensure we escape them
        os:
          - ubuntu-latest
          - windows-latest
          - macOS-latest
      fail-fast: false
    env:
      JULIA_DEPOT_PATH: /tmp/julia-depot
    steps:
    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11
    - name: Set cache-name
      id: cache-name
      run: |
        echo "cache-name=${{ needs.generate-prefix.outputs.cache-prefix }}-matrix" >>"$GITHUB_OUTPUT"
    - name: Save cache
      id: cache
      uses: ./
      with:
        cache-name: ${{ steps.cache-name.outputs.cache-name }}
        delete-old-caches: required
    - name: Check no artifacts dir
      shell: 'julia --color=yes {0}'
      run: |
        dir = joinpath(first(DEPOT_PATH), "artifacts")
        @assert !isdir(dir)
    - name: Install a small binary
      shell: 'julia --color=yes {0}'
      run: 'using Pkg; Pkg.add(PackageSpec(name="${{ matrix.dep.name }}", version="${{ matrix.dep.version }}"))'

  # Do tests with no matrix also given the matrix is auto-included in cache key
  test-save-nomatrix:
    needs: generate-prefix
    runs-on: ubuntu-latest
    outputs:
      cache-name: ${{ steps.cache-name.outputs.cache-name }}
    steps:
    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11
    - name: Set cache-name
      id: cache-name
      run: |
        echo "cache-name=${{ needs.generate-prefix.outputs.cache-prefix }}-nomatrix" >>"$GITHUB_OUTPUT"
    - name: Save cache
      id: cache
      uses: ./
      with:
        cache-name: ${{ steps.cache-name.outputs.cache-name }}
        delete-old-caches: required
    - name: Check no artifacts dir
      shell: 'julia --color=yes {0}'
      run: |
        dir = joinpath(first(DEPOT_PATH), "artifacts")
        @assert !isdir(dir)
    - name: Install a small binary
      shell: 'julia --color=yes {0}'
      run: 'using Pkg; Pkg.add("pandoc_jll")'

  test-restore:
    needs: test-save
    runs-on: ${{ matrix.os }}
    strategy:
      matrix:
        dep:
          - name: pandoc_jll
            version: "3"
            invalid-chars: ","  # Use invalid characters in job matrix to ensure we escape them
        os:
          - ubuntu-latest
          - windows-latest
          - macOS-latest
      fail-fast: false
    env:
      JULIA_DEPOT_PATH: /tmp/julia-depot
    steps:
    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11
    - name: Restore cache
      id: cache
      uses: ./
      with:
        cache-name: ${{ needs.test-save.outputs.cache-name }}
        # Cannot require a successful cache delete on forked PRs as the permissions for actions is limited to read
        delete-old-caches: ${{ github.event.pull_request.head.repo.fork && 'false' || 'required' }}
    - name: Test cache-hit output
      shell: 'julia --color=yes {0}'
      run: |
        @show ENV["cache-hit"]
        @assert ENV["cache-hit"] == "true"
      env:
        cache-hit: ${{ steps.cache.outputs.cache-hit }}
    - name: Check existance or emptiness of affected dirs
      shell: 'julia --color=yes {0}'
      run: |
        # These dirs should exist as they've been cached
        artifacts_dir = joinpath(first(DEPOT_PATH), "artifacts")
        @assert !isempty(readdir(artifacts_dir))
        packages_dir = joinpath(first(DEPOT_PATH), "packages")
        @assert !isempty(readdir(packages_dir))
        compiled_dir = joinpath(first(DEPOT_PATH), "compiled")
        @assert !isempty(readdir(compiled_dir))
        scratchspaces_dir = joinpath(first(DEPOT_PATH), "scratchspaces")
        @assert !isempty(readdir(scratchspaces_dir))
        logs_dir = joinpath(first(DEPOT_PATH), "logs")
        @assert !isempty(readdir(logs_dir))

  test-restore-nomatrix:
    needs: test-save-nomatrix
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@b4ffde65f46336ab88eb53be808477a3936bae11
    - name: Restore cache
      id: cache
      uses: ./
      with:
        cache-name: ${{ needs.test-save-nomatrix.outputs.cache-name }}
        # Cannot require a successful cache delete on forked PRs as the permissions for actions is limited to read
        delete-old-caches: ${{ github.event.pull_request.head.repo.fork && 'false' || 'required' }}
    - name: Test cache-hit output
      shell: 'julia --color=yes {0}'
      run: |
        @show ENV["cache-hit"]
        @assert ENV["cache-hit"] == "true"
      env:
        cache-hit: ${{ steps.cache.outputs.cache-hit }}
    - name: Check existance or emptiness of affected dirs
      shell: 'julia --color=yes {0}'
      run: |
        # These dirs should exist as they've been cached
        artifacts_dir = joinpath(first(DEPOT_PATH), "artifacts")
        @assert !isempty(readdir(artifacts_dir))
        packages_dir = joinpath(first(DEPOT_PATH), "packages")
        @assert !isempty(readdir(packages_dir))
        compiled_dir = joinpath(first(DEPOT_PATH), "compiled")
        @assert !isempty(readdir(compiled_dir))
        scratchspaces_dir = joinpath(first(DEPOT_PATH), "scratchspaces")
        @assert !isempty(readdir(scratchspaces_dir))
        logs_dir = joinpath(first(DEPOT_PATH), "logs")
        @assert !isempty(readdir(logs_dir))
